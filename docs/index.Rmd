---
title: "A/B Test of BM25 Search Ranking"
subtitle: "Almost First Draft"
author:
- <a href = 'https://meta.wikimedia.org/wiki/User:EBernhardson_(WMF)'>Erik Bernhardson</a> (Engineering)
- <a href = 'https://www.mediawiki.org/wiki/User:DCausse_(WMF)'>David Causse</a> (Engineering)
- <a href = 'https://meta.wikimedia.org/wiki/User:TJones_(WMF)'>Trey Jones</a> (Engineering & Review)
- <a href = 'https://meta.wikimedia.org/wiki/User:MPopov_(WMF)'>Mikhail Popov</a> (Analysis & Report)
- <a href = 'https://meta.wikimedia.org/wiki/User:DTankersley_(WMF)'>Deb Tankersley</a> (Product Management)
- <a href = 'https://meta.wikimedia.org/wiki/User:CXie_(WMF)'>Chelsy Xie</a> (Review)
date: "`r as.character(Sys.Date(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    css: style.css
    fig_caption: yes
    fig_width: 10
    fig_height: 6
    highlight: zenburn
    keep_md: yes
    mathjax: https://tools-static.wmflabs.org/cdnjs/ajax/libs/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML
    md_extensions: +raw_html +markdown_in_html_blocks +tex_math_dollars +fancy_lists +startnum +lists_without_preceding_blankline
    self_contained: no
    theme: flatly
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: no
---
<script language="JavaScript">
$(function() {
  /* Lets the user click on the images to view them in full resolution. */
  $("div.figure img").wrap(function() {
    var link = $('<a/>');
    link.attr('href', $(this).attr('src'));
    link.attr('title', $(this).attr('alt'));
    link.attr('target', '_blank');
    return link;
  });
});
</script>
<p>{ <a href="https://github.com/wikimedia-research/Discovery-Search-Test-BM25/blob/master/docs/index.Rmd">RMarkdown Source</a> | <a href="https://github.com/wikimedia-research/Discovery-Search-Test-BM25">Analysis Codebase</a> }</p>
```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
options(digits = 3, scipen = 500)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE, autodep = TRUE)
path <- function(x) {
  if (grepl("docs", getwd(), fixed = TRUE)) {
    return(file.path("..", x))
  } else {
    return(x)
  }
}
```
```{r packages}
# Load packages that we will be using in this report:

# install.packages("devtools")
# devtools::install_github("hadley/ggplot2")
# ^ development version of ggplot2 includes subtitles
# devtools::install_github("wikimedia/wikimedia-discovery-polloi")
# ^ for compressing 100000 into 100K

library(tidyverse) # install.packages("tidyverse")
# ^ for ggplot2, dplyr, tidyr, broom, etc.

library(binom) # install.packages("binom")
# ^ for Bayesian confidence intervals of proportions

# Font to go together with HTML version of report: http://www.latofonts.com/
# extrafont::font_import("~/Downloads/Lato2OFL")
```
```{r captions, echo = FALSE}
# Manual figure & table captioning:
library(captioner) # install.packages("captioner")
table_caps <- captioner(prefix = "Table")
figure_caps <- captioner(prefix = "Figure")
code_caps <- captioner(prefix = "Snippet")
# Custom caption formatting and printing:
format_caption <- function(caps, name) {
  return({
    sub(caps(name, display = "cite"),
      paste0("**", caps(name, display = "cite"),"**"),
      caps(name, display = "full"), fixed = TRUE) %>%
    sub("  ", " ", ., fixed = TRUE)
  })
}
print_caption <- function(formatted_caption) {
  cat(paste0('<p class = "caption">', formatted_caption, '</p>', collapse = ''))
}
# Add captions:
code_caps(name = "bm25_query", caption = "Query used to extract BM25 test data from our event logging database.", display = FALSE)
table_caps(name = "group_counts", caption = "Counts of sessions anonymously tracked and events collected during the one-week-long A/B test.", display = FALSE)
figure_caps("query_reform_counts", "Proportions of searches with 0, 1, 2, and 3+ query reformulations.", display = FALSE)
figure_caps("query_reform_prop", "Proportions of searches where user reformulated their query.", display = FALSE)
figure_caps("zrr", "Zero results rate is the proportion of searches in which the user received zero results.", display = FALSE)
figure_caps("paulscore", "Average per-group PaulScore for various values of F (0.1, 0.5, and 0.9) with bootstrapped confidence intervals.", display = FALSE)
figure_caps("engagement", "Clickthrough rates of test groups after splitting searches into those having query reformulations and those without query reformulations.", display = FALSE)
figure_caps("first_clicked", "First clicked result's position by group.", display = FALSE)
```

## Executive Summary

In order to improve the relevancy of search results, Discovery's Search team has decided to test a new document ranking method called BM25, which would replace the term frequency–inverse document frequency (tf–idf) method that is currently used. We saw the following results from our analysis:

Same query builder as control group but using BM25 as similarity function
:   For searches made by users in this group, we use the same query builder as we use for the control group but we switched the similarity function to BM25 and employ a weighted sum for the incoming links query independant factor (QIF). Users in this group were less likely to click on the 1st search result and instead more likely to click on the second search result. They were also more likely to reformulate their query. With regards to zero results rate (ZRR), PaulScore, and engagement, users in this group were very similar to users in the control group.

Using per-field query building with incoming links as QIF
:   For searches made by users in this group, we use BM25 similarity and switch to a per-field query builder using only incoming links as a query independant factor. This group had the second-highest PaulScores and engagement, both in searches where the user reformulated their query and in searches without query reformulation. Users in this group were more likely to click on the first search result than users in the control group.

Using per-field query builder with incoming links and pageviews as QIFs
:   Similar to the group described above but we added pageviews as an additional query independent factor for searches made by users in this group. This group had the highest PaulScores and engagement, both in searches where the user reformulated their query and in searches without query reformulation. Users in this group were a lot more likely to click on the first search result than users in the control group.

Track typos in first 2 characters
:   Similar to the group described above (*using per-field query builder with incoming links and pageviews as QIFs*), but with an additional field to track typos in the first two characters. This group had the lowest ZRR, and its ZRR was statistically significantly smaller than the control group's ZRR. This group also had the smallest proportion of searches where the user reformulated their query. Users in this group were a lot more likely to click on the first search result than users in the control group.

We recommend switching to BM25 ranking with incoming links (and possibly pageviews) as query-independent factors, as this configuration appears to give users results that are more relevant and that they engage with more (especially the first search result).

## Background

The Discovery department's mission is to help users discover and access knowledge on Wikipedia and other Wikimedia projects. One of the goals of Discovery's Search team is to improve the relevance of results when users search Wikipedia and its sister projects. Currently, our search engine uses [term frequency–inverse document frequency (tf–idf)](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to rank articles. To improve the search results, we decided to try a new document-ranking function: [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25). To assess the efficacy of the proposed switch, we ran an A/B test for 10 days and anonymously tracked randomly sampled search sessions. Some users received search results acquired through the tf–idf method, while others received search results acquired through BM25 with various configurations. We are primarily interested in:

* __Zero results rate__, the proportion of searches that yielded zero results (smaller is better)
* __Users' engagement__ with the search results, measured as the clickthrough rate (bigger is better)
* __PaulScore__, a metric of search results' relevancy that relies on the position of the clicked result[s] (bigger is better)
* __Query reformulation__ -- the less times the user reformulated their query, the better our search engine performs (within reason, as we can only do so much with misspelled words)  

## Methods

### Data

Users who searched English Wikipedia ("EnWiki") had a 1 in 66 chance of being selected for search satisfaction tracking according to our [TestSearchSatisfaction2 #15700292)](https://meta.wikimedia.org/w/index.php?title=Schema:TestSearchSatisfaction2&oldid=15700292) schema. See change [307536](https://gerrit.wikimedia.org/r/#/c/307536/) on Gerrit for more details. Those users who were on EnWiki and were randomly selected to have their sessions anonymously tracked then had a 2 in 3 chance of being selected for the BM25 test. Users who were randomly selected for the A/B test were then randomly assigned to one of the following five groups:

Control Group (tf–idf)
:   Identical to what we serve to our users today plus an artificial latency to compensate the fact that we run the other buckets on another data center. (nDCG<sub>5</sub> score on Discernatron: 0.2772)

Same query builder as control group but using BM25 as similarity function
:   For searches made by users in this group, we use the same query builder as we use for the control group but we switched the similarity function to BM25 and employ a weighted sum for the incoming links query independant factor (QIF). We expected this bucket to behave poorly in term of clickthrough compared to the control group. We included this group confirm our assumptions that the current query builder and the "all field" approach is not designed for the BM25 similarity. (nDCG<sub>5</sub> score on Discernatron: 0.2689)

Using per-field query building with incoming links as QIF
:   For searches made by users in this group, we use BM25 similarity and switch to a per-field query builder using only incoming links as a query independant factor. This is the best contender according to Discernatron. We expect an increase in clickthrough because it tends rank obvious matches in the top 3. (nDCG<sub>5</sub> score on Discernatron: 0.3362)

Using per-field query builder with incoming links and pageviews as QIFs
:   Similar to the group described above but we added pageviews as an additional query independent factor for searches made by users in this group. The weight for pageviews is still very low compared to incoming links and this test is mostly to see how pageviews could affect the ranking. We expect a very minimal difference in behavior compared to group _using per-field query building with incoming links as QIF_. (nDCG<sub>5</sub> score on Discernatron: 0.3359)

Track typos in first 2 characters
:   Similar to the group described above, but with an additional field to track typos in the first two characters. We expect a slight decrease in zero result rate and hope for an increase in clickthrough rate. This test is added to measure the benefit of such field. The question of interest we hope to answer is: Will this increase in noise provide more annoying suggestions or will it help our users? (This feature can't be really tested with Discernatron today.)

For all the groups listed above, we include the normalized [discounted cumulative gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) ([nDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG)) score -- a measure of ranking quality -- computed from ranking data collected through [Discernatron](https://www.mediawiki.org/wiki/Wikimedia_Discovery/Search/Glossary#Discernatron), a tool that allows participants to judge the relevance of search results to help the Search team be able to test changes before making them available on-wiki.

The full-text (as opposed to auto-complete) searching event logging data was extracted from the database using the following SQL query:

```sql
SELECT
  LEFT(`timestamp`, 8) AS date,
  event_subTest AS test_group,
  `timestamp` AS ts,
  event_uniqueId AS event_id,
  event_mwSessionId AS session_id,
  event_searchSessionId AS search_id,
  event_pageViewId AS page_id,
  event_searchToken AS cirrus_id,
  CAST(event_query AS CHAR CHARACTER SET utf8) AS query,
  event_hitsReturned AS n_results_returned,
  event_msToDisplayResults AS load_time,
  CASE WHEN event_action = 'searchResultPage' THEN 'SERP' ELSE 'click' END AS action,
  event_position AS position_clicked
FROM TestSearchSatisfaction2_15700292
WHERE
  LEFT(`timestamp`, 8) >= '20160830' AND LEFT(`timestamp`, 8) <= '20160910'
  AND event_source = 'fulltext'
  AND LEFT(event_subTest, 4) = 'bm25'
  AND (
    (event_action = 'searchResultPage' AND event_hitsReturned IS NOT NULL AND event_msToDisplayResults IS NOT NULL)
    OR
    (event_action = 'click' AND event_position IS NOT NULL AND event_position > -1)
  )
ORDER BY date, wiki, session_id, search_id, page_id, action DESC, timestamp;
```

```{r sql_query_caption, results = "asis", echo = FALSE}
print_caption(format_caption(code_caps, "bm25_query"))
```

### Query Reformulation Detection

```{r query_clustering_functions}
overlapping_results <- function(x) {
  if (all(is.na(x))) {
    return(diag(length(x)))
  }
  input <- strsplit(stringr::str_replace_all(x, "[\\[\\]]", ""), ",")
  output <- vapply(input, function(y) {
    temp <- vapply(input, function(z) { length(intersect(z, y)) }, 0L)
    # Normalize by diving by number of possible matches
    # e.g. if two queries have two results each that are
    #      exactly the same, that's worth more than if
    #      two queries have 20 results each but have
    #      only three in common
    temp <- temp/pmin(rep(length(y), length(input)), vapply(input, length, 0L))
    temp[is.na(x)] <- 0L
    return(temp)
  }, rep(0.0, length(input)))
  diag(output) <- 1L
  return(output)
}

cluster_queries <- function(queries, results, linkage = c("complete", "single", "average"), threshold = NULL, debug = FALSE) {
  if (length(queries) < 2) {
    return(1)
  }
  input <- data.frame(query = queries, stringsAsFactors = FALSE)
  x <- do.call(rbind, lapply(input$query, function(x) {
    # Compute for each x in input$query the normalized edit distance from x to input$query:
    normalized_distances <- adist(tolower(x), tolower(input$query), fixed = TRUE)/max(nchar(input$query))
    # Return:
    return(normalized_distances)
  }))
  # Decrease distance of queries that share results:
  overlaps <- overlapping_results(results)
  x <- x * (10^(-overlaps))
  # ^ if two queries have the exact same results, we make the new
  #   edit distance 0.1 of what their original edit distance is
  # Create distance object:
  y <- x[lower.tri(x, diag = FALSE)]
  d <- structure(
    y, Size = length(queries), Labels = queries, Diag = FALSE, Upper = FALSE,
    method = "levenshtein", class = "dist", call = match.call()
  )
  clustering_tree <- hclust(d, method = linkage[1])
  # When using average linkage, we may end up with funky trees
  #   that cannot be properly cut. So this logic helps against
  #   errors and yieds NAs instead.
  clusters <- tryCatch(
    cutree(clustering_tree, h = threshold),
    error = function(e) { return(NA) })
  if (all(is.na(clusters))) {
    clusters <- rep(clusters, nrow(input))
    names(clusters) <- input$query
  }
  output <- left_join(
    input,
    data.frame(query = names(clusters),
               cluster = as.numeric(clusters),
               stringsAsFactors = FALSE),
    by = "query")
  if (debug) {
    return(
      list(
        original_distances = x / (10^(-overlaps)),
        overlaps = overlaps,
        modified_distances = d,
        output = output,
        hc = clustering_tree
      )
    )
  }
  return(output$cluster)
}
```

Sed finibus magna eu turpis laoreet, eu convallis ex convallis. Suspendisse potenti. Maecenas bibendum nunc at leo iaculis laoreet. Cras eros libero, sollicitudin sed ligula quis, molestie rutrum est. Aenean pharetra volutpat luctus. Nulla facilisi. Ut rutrum, augue ac faucibus maximus, dui sem lacinia lectus, ut egestas dui ligula sed enim. Nunc tincidunt velit eu augue tincidunt maximus. Nam nec ante nec lacus iaculis fringilla eu non turpis. Duis id urna vehicula, mattis urna sed, condimentum neque. Nunc eget lectus elementum, imperdiet odio suscipit, tristique mauris.

### PaulScore Definition

PaulScore[[1]](#ref-1) is computed via the following steps:

#. Pick scoring factor $0 < F < 1$.
#. For $i$-th search session $S_i$ $(i = 1, \ldots, n)$ containing $m$ queries $Q_1, \ldots, Q_m$ and search result sets $\mathbf{R}_1, \ldots, \mathbf{R}_m$:
    (#) For each $j$-th search query $Q_j$ with result set $\mathbf{R}_j$, let $\nu_j$ be the query score: $$\nu_j = \sum_{k~\in~\{\text{0-based positions of clicked results in}~\mathbf{R}_j\}} F^k.$$
    (#) Let user's average query score $\bar{\nu}_{(i)}$ be $$\bar{\nu}_{(i)} = \frac{1}{m} \sum_{j = 1}^m \nu_j.$$
#. Then the PaulScore is the average of all users' average query scores: $$\text{PaulScore}(F)~=~\frac{1}{n} \sum_{i = 1}^n \bar{\nu}_{(i)}.$$

We can calculate the confidence interval of PaulScore$(F)$ by approximating its distribution via [boostrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)).

```{r paulscore_functions}
# PaulScore Calculation
query_score <- function(positions, F) {
   if (length(positions) == 1 || all(is.na(positions))) {
    # no clicks were made
    return(0)
   } else {
     positions <- positions[!is.na(positions)] # when operating on 'events' dataset, SERP events won't have positions
  return(sum(F^positions))
   }
}
# Bootstrapping
bootstrap_mean <- function(x, m, seed = NULL) {
  if (!is.null(seed)) {
    set.seed(seed)
  }
  n <- length(x)
  return(replicate(m, mean(x[sample.int(n, n, replace = TRUE)])))
}
```

## Results
```{r data}
# Import events fetched from MySQL
load(path("data/ab-test_bm25.RData"))
events$test_group <- factor(
  events$test_group,
  levels = c("bm25:control", "bm25:allfield", "bm25:inclinks", "bm25:inclinks_pv", "bm25:inclinks_pv_rev"),
  labels = c("Control Group (tf–idf)", "Same query builder as control group but using BM25 as similarity function", "Using per-field query building with incoming links as QIF", "Using per-field query builder with incoming links and pageviews as QIFs", "Track typos in first 2 characters"))
cirrus <- readr::read_tsv(path("data/ab-test_bm25_cirrus-results.tsv.gz"), col_types = "ccc")
events <- left_join(events, cirrus, by = c("event_id", "page_id"))
rm(cirrus)
```
The test was deployed on September 1st and ran for 10 days, collecting a total of `r polloi::compress(nrow(events), 1)` events from `r polloi::compress(length(unique(events$search_id)), 1)` unique sessions. See `r table_caps("group_counts", display = "cite")` for counts broken down by test group.

```{r summary, results = "asis", dependson = "data"}
events_summary <- events %>%
  group_by(`Test group` = test_group) %>%
  summarize(`Search sessions` = length(unique(search_id)), `Events recorded` = n()) %>%
  {
    rbind(., tibble(
      `Test group` = "Total",
      `Search sessions` = sum(.$`Search sessions`),
      `Events recorded` = sum(.$`Events recorded`)
    ))
  } %>%
  mutate(`Search sessions` = prettyNum(`Search sessions`, big.mark = ","),
         `Events recorded` = prettyNum(`Events recorded`, big.mark = ","))
knitr::kable(events_summary, format = "markdown", align = c("l", "r", "r"))
```

```{r summary_caption, results = "asis", echo = FALSE}
print_caption(format_caption(table_caps, "group_counts"))
```

### SERP De-duplication

Duis massa dolor, luctus nec purus sed, euismod condimentum neque. Maecenas laoreet mauris at dui consequat gravida. Curabitur ut consequat lacus. In libero sem, dignissim ac ultricies eget, ornare eu ex. Phasellus sed lacus malesuada, luctus sapien et, gravida risus. Phasellus sed tempor metus. Morbi a dignissim tellus.

```{r serp_deduplication, dependson = "data"}
# Correct for when user uses pagination or uses back button to go back to SERP after visiting a result.
# Start by assigning the same page_id to different SERPs that have exactly the same query:
temp <- events %>%
  filter(action == "SERP") %>%
  group_by(session_id, search_id, query) %>%
  mutate(new_page_id = min(page_id)) %>%
  ungroup %>%
  select(c(page_id, new_page_id)) %>%
  distinct
# We also need to do the same for associated click events:
events <- left_join(events, temp, by = "page_id"); rm(temp)
# Find out which SERPs are duplicated:
temp <- events %>%
  filter(action == "SERP") %>%
  arrange(new_page_id, ts) %>%
  mutate(dupe = duplicated(new_page_id, fromLast = FALSE)) %>%
  select(c(event_id, dupe))
events <- left_join(events, temp, by = "event_id"); rm(temp)
events$dupe[events$action == "click"] <- FALSE
# Remove duplicate SERPs and re-sort:
events <- events[!events$dupe & !is.na(events$new_page_id), ] %>%
  select(-c(page_id, dupe)) %>%
  rename(page_id = new_page_id) %>%
  arrange(date, session_id, search_id, page_id, desc(action), ts)
```
```{r aggregation, dependson = "serp_deduplication"}
# Summarize on a page-by-page basis:
searches <- events %>%
  group_by(`test group` = test_group, session_id, search_id, page_id) %>%
  filter("SERP" %in% action) %>% # filter out searches where we have clicks but not SERP events
  summarize(ts = ts[1], query = query[1],
            results = ifelse(n_results_returned[1] > 0, "some", "zero"),
            clickthrough = "click" %in% action,
            `first clicked result's position` = ifelse(clickthrough, position_clicked[2], NA),
            `result page IDs` = result_pids[1],
            `Query score (F=0.1)` = query_score(position_clicked, 0.1),
            `Query score (F=0.5)` = query_score(position_clicked, 0.5),
            `Query score (F=0.9)` = query_score(position_clicked, 0.9)) %>%
  arrange(ts)
# Cluster queries
safe_clust <- function(search_id, page_ids, queries, results, threshold, linkage) {
  clusters <- cluster_queries(queries, results, linkage, threshold)
  if (length(clusters) != length(page_ids)) {
    stop("Number of cluster labels does not match number of searches for search session ", unlist(search_id)[1])
  } else {
    return(clusters)
  }
}
```
```{r query_clustering, dependson = "aggregation"}
searches <- searches %>%
  group_by(`test group`, session_id, search_id) %>%
  mutate(
    cluster_single = safe_clust(search_id, page_id, query, `result page IDs`, 0.3, "single"),
    cluster_average = safe_clust(search_id, page_id, query, `result page IDs`, 0.433, "average"),
    cluster_complete = safe_clust(search_id, page_id, query, `result page IDs`, 0.377, "complete")
  )
```
```{r query_reformulations, dependson = "query_clustering"}
most_common <- function(x) {
  if (all(is.na(x))) {
    return(as.character(NA))
  } else {
     return(names(sort(table(x), decreasing = TRUE))[1])
  }
}

summarize_reformulations <- function(grouped_data) {
  return({
    grouped_data %>%
      # Count number of similar searches made in a single search session
      # (multiple search sessions per MW session allowed)
      summarize(
        reformulations = n() - 1,
        clickthrough = any(clickthrough),
        results = ifelse("some" %in% results, "some", "zero"),
        `most popular position clicked first` = most_common(`first clicked result's position`),
        `Cluster score (F=0.1)` = mean(`Query score (F=0.1)`, na.rm = TRUE),
        `Cluster score (F=0.5)` = mean(`Query score (F=0.5)`, na.rm = TRUE),
        `Cluster score (F=0.9)` = mean(`Query score (F=0.9)`, na.rm = TRUE)
      ) %>%
      ungroup
  })
}

set.seed(0) # for reproducibility
query_reformulations_single <- searches %>%
  group_by(`test group`, session_id, search_id, cluster = cluster_single) %>%
  summarize_reformulations
query_reformulations_complete <- searches %>%
  group_by(`test group`, session_id, search_id, cluster = cluster_complete) %>%
  summarize_reformulations
query_reformulations_average <- searches %>%
  ungroup %>%
  filter(!is.na(cluster_average)) %>%
  group_by(`test group`, session_id, search_id, cluster = cluster_average) %>%
  summarize_reformulations
query_reformulations <- bind_rows(
  "Queries grouped via average linkage" = query_reformulations_average,
  "Queries grouped via complete linkage" = query_reformulations_complete,
  "Queries grouped via single linkage" = query_reformulations_single,
  .id = "linkage")
rm(query_reformulations_average, query_reformulations_complete, query_reformulations_single)
```

### Query Reformulation

In Figures `r figure_caps("query_reform_counts", display = "num")` and `r figure_caps("query_reform_prop", display = "num")`, we see...

```{r query_reformulations_counts_caption, echo = FALSE}
query_reform_counts_cap <- format_caption(figure_caps, "query_reform_counts")
```
```{r query_reformulations_counts_eda, fig.cap = query_reform_counts_cap, dependson = "query_reformulations"}
# Calculate proportions of searches with 0, 1, 2, 3+ query reformulations
query_reformulations %>%
  mutate(`query reformulations` = forcats::fct_lump(factor(reformulations), 3, other_level = "3+")) %>%
  group_by(linkage, `test group`, `query reformulations`) %>%
  tally %>%
  mutate(proportion = n/sum(n)) %>%
  ggplot(aes(x = `query reformulations`, y = proportion, fill = `test group`)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  facet_wrap(~ linkage, ncol = 3) +
  labs(y = "Proportion of searches", x = "Approximate number of query reformulations per search session",
       title = "Number of query reformulations by test group and linkage",
       subtitle = "Queries were grouped via hierarchical clustering using average/complete/single linkage and edit distance adjusted by search results in common") +
  theme_minimal(base_family = "Lato") +
  theme(legend.position = "bottom",
        strip.background = element_rect(fill = "gray90"),
        panel.border = element_rect(color = "gray30", fill = NA))
```

```{r query_reformulations_prop, dependson = "query_reformulations"}
# Calculate proportion of searches where user reformulated their query
reformulation_counts <- query_reformulations %>%
  group_by(linkage, `test group`) %>%
  summarize(`searches with query reformulations` = sum(reformulations > 0),
            searches = n(),
            proportion = `searches with query reformulations`/searches) %>%
  ungroup
reformulation_counts <- cbind(
  reformulation_counts,
  as.data.frame(
    binom:::binom.bayes(
      reformulation_counts$`searches with query reformulations`,
      n = reformulation_counts$searches)[, c("mean", "lower", "upper")]
  )
)
```
```{r query_reformulations_prop_caption, echo = FALSE}
query_reform_prop_cap <- format_caption(figure_caps, "query_reform_prop")
```
```{r query_reformulations_prop_eda, fig.cap = query_reform_prop_cap, dependson = "query_reformulations_prop"}
reformulation_counts %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_hline(aes(yintercept = mean), linetype = "dashed", color = RColorBrewer::brewer.pal(3, "Set1")[1],
             data = filter(reformulation_counts, `test group` == "Control Group (tf–idf)")) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  scale_y_continuous(labels = scales::percent_format(),
                     breaks = seq(.16, .24, 0.01),
                     minor_breaks = seq(.16, .24, 0.005),
                     expand = c(0.01, 0.01)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  facet_wrap(~ linkage, ncol = 3) +
  geom_text(aes(label = sprintf("%.1f%%", 100 * proportion), y = upper + 0.005, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  labs(y = "% of searches with query reformulations", x = NULL,
       title = "Searches with reformulated queries by test group (and linkage)",
       subtitle = "Queries were grouped via hierarchical clustering using average/complete/single linkage and edit distance adjusted by search results in common") +
  theme_minimal(base_family = "Lato") +
  theme(legend.position = "bottom",
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        strip.background = element_rect(fill = "gray90"),
        panel.border = element_rect(color = "gray30", fill = NA))
```

### Zero Results Rate

In `r figure_caps("zrr", display = "cite")`, we see...

```{r zrr, dependson = "query_clustering"}
zrr_pages <- searches %>%
  group_by(`test group`, results) %>%
  tally %>%
  spread(results, n) %>%
  mutate(`zero results rate` = zero/(some + zero)) %>%
  ungroup
zrr_pages <- cbind(zrr_pages, as.data.frame(binom:::binom.bayes(zrr_pages$zero, n = zrr_pages$some + zrr_pages$zero)[, c("mean", "lower", "upper")]))
```
```{r zrr_caption, echo = FALSE}
zrr_cap <- format_caption(figure_caps, "zrr")
```
```{r zrr_eda, fig.cap = zrr_cap, dependson = "zrr"}
zrr_pages %>%
  ggplot(aes(x = `test group`, y = `mean`)) +
  geom_hline(
    yintercept = zrr_pages$`mean`[zrr_pages$`test group` == "Control Group (tf–idf)"],
    linetype = "dashed", color = "gray50") +
  geom_pointrange(aes(ymin = lower, ymax = upper)) +
  scale_x_discrete(limits = rev(levels(events$test_group))) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = NULL, y = "Zero Results Rate",
       title = "Proportion of searches that did not yield any results, by test group",
       subtitle = "With 95% credible intervals. Dashed line represents the baseline (ZRR of the control group).") +
  geom_text(aes(label = sprintf("%.2f%%", 100 * `zero results rate`),
                vjust = "bottom", hjust = "center"), nudge_x = 0.1) +
  coord_flip() +
  theme_minimal(base_family = "Lato")
```

### PaulScore

In `r figure_caps("paulscore", display = "cite")`, we see...

```{r paulscores, dependson = "query_clustering"}
set.seed(0) # for reproducibility
paulscores <- searches %>%
  ungroup %>%
  select(c(`test group`, `Query score (F=0.1)`, `Query score (F=0.5)`, `Query score (F=0.9)`)) %>%
  gather(`F value`, `Query score`, -`test group`) %>%
  mutate(`F value` = sub("^Query score \\(F=(0\\.[159])\\)$", "F = \\1", `F value`)) %>%
  group_by(`test group`, `F value`) %>%
  summarize(
    PaulScore = mean(`Query score`),
    Interval = paste0(quantile(bootstrap_mean(`Query score`, 1000), c(0.025, 0.975)), collapse = ",")
  ) %>%
  extract(Interval, into = c("Lower", "Upper"), regex = "(.*),(.*)", convert = TRUE)
```

```{r paulscores_caption, echo = FALSE}
paulscore_cap <- format_caption(figure_caps, "paulscore")
```
```{r paulscores_eda, fig.cap = paulscore_cap, dependson = "paulscores"}
paulscores %>%
  ggplot(aes(x = `F value`, y = PaulScore, color = `test group`)) +
  geom_pointrange(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.7)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  scale_y_continuous(limits = c(0.2, 0.35)) +
  labs(x = NULL, y = "PaulScore(F)",
       title = "PaulScore(F) by test group and value of F",
       subtitle = "With bootstrapped 95% confidence intervals. Dashed line indicates baseline (control group) for comparing test groups.") +
  geom_text(aes(label = sprintf("%.3f", PaulScore), y = Upper + 0.01, vjust = "bottom"),
            position = position_dodge(width = 0.7)) +
  theme_minimal(base_family = "Lato") +
  theme(legend.position = "bottom") +
  annotate("segment",
           x = (0:2) + 0.6, xend = (1:3) + 0.4,
           y = paulscores$PaulScore[paulscores$`test group` == "Control Group (tf–idf)"],
           yend = paulscores$PaulScore[paulscores$`test group` == "Control Group (tf–idf)"],
           color = RColorBrewer::brewer.pal(3, "Set1")[1],
           linetype = "dashed")
```

### Engagement

In `r figure_caps("engagement", display = "cite")`, we see...

```{r engagement, dependson = "query_reformulations"}
# Figure out engagement (clickthroughs) on a per-search ("query cluster") basis:
per_search_engagement <- query_reformulations %>%
  filter(results == "some") %>%
  group_by(`test group`, linkage,
           search = paste(search_id, cluster),
           reformulated = reformulations > 0) %>%
  summarize(clickthroughs = sum(clickthrough), `non-ZR searches` = n())

engagement <- per_search_engagement %>%
  group_by(`test group`, linkage,
           reformulated = ifelse(reformulated, "reformulated query", "did not reformulate query")) %>%
  summarize(clickthroughs = sum(clickthroughs > 0),
            searches = n(), ctr = clickthroughs/searches) %>%
  ungroup
engagement <- cbind(
  engagement,
  as.data.frame(
    binom:::binom.bayes(
      engagement$clickthroughs,
      n = engagement$searches)[, c("mean", "lower", "upper")]
    )
  )
```
```{r engagement_caption, echo = FALSE}
engagement_cap <- format_caption(figure_caps, "engagement")
```
```{r engagement_eda, fig.cap = engagement_cap, dependson = "engagement"}
engagement %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_hline(aes(yintercept = mean), linetype = "dashed", color = RColorBrewer::brewer.pal(3, "Set1")[1],
             data = filter(engagement, `test group` == "Control Group (tf–idf)")) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  facet_grid(reformulated ~ linkage, scales = "free_y") +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  scale_y_continuous(labels = scales::percent_format(), expand = c(0.01, 0.01)) +
  labs(x = NULL, y = "Clickthrough rate",
       title = "Engagement with search results by test group and presence of query reformulation",
       subtitle = "Queries were grouped via hierarchical clustering using average/complete/single linkage and edit distance adjusted by search results in common") +
  geom_text(aes(label = sprintf("%.1f%%", 100 * ctr), y = upper + 0.005, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  theme_minimal(base_family = "Lato") +
  theme(legend.position = "bottom",
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        strip.background = element_rect(fill = "gray90"),
        panel.border = element_rect(color = "gray30", fill = NA))
```

### First Clicked Result's Position

In `r figure_caps("first_clicked", display = "cite")`, we see...

```{r first_clicked_position, dependson = "query_reformulations"}
safe_ordinals <- function(x) {
  return(vapply(x, toOrdinal::toOrdinal, ""))
}
first_clicked <- searches %>%
  filter(results == "some" & clickthrough & !is.na(`first clicked result's position`)) %>%
  mutate(`first clicked result's position` = ifelse(`first clicked result's position` < 4, safe_ordinals(`first clicked result's position` + 1), "5th or higher")) %>%
  group_by(`test group`, `first clicked result's position`) %>%
  tally %>%
  mutate(total = sum(n), prop = n/total) %>%
  ungroup
set.seed(0)
temp <- as.data.frame(binom:::binom.bayes(first_clicked$n, n = first_clicked$total, tol = .Machine$double.eps^0.1)[, c("mean", "lower", "upper")])
first_clicked <- cbind(first_clicked, temp); rm(temp)
```
```{r first_clicked_position_caption, echo = FALSE}
first_clicked_cap <- format_caption(figure_caps, "first_clicked")
```
```{r first_clicked_position_eda, fig.cap = first_clicked_cap, dependson = "first_clicked_position"}
first_clicked %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_hline(
    aes(yintercept = mean), 
    linetype = "dashed", color = RColorBrewer::brewer.pal(3, "Set1")[1],
    data = filter(first_clicked, `test group` == "Control Group (tf–idf)")
  ) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  geom_text(aes(label = sprintf("%.1f", 100 * prop), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  scale_y_continuous(labels = scales::percent_format(),
                     expand = c(0, 0.005), breaks = seq(0, 1, 0.01)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  facet_wrap(~ `first clicked result's position`, scale = "free_y", nrow = 1) +
  labs(x = NULL, y = "Proportion of searches",
       title = "Position of the first clicked result",
       subtitle = "With 95% credible intervals") +
  theme_minimal(base_family = "Lato") +
  theme(legend.position = "bottom",
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        strip.background = element_rect(fill = "gray90"),
        panel.border = element_rect(color = "gray30", fill = NA))
```

## References

### Reading

<ol><li id="ref-1"><a href = "https://www.mediawiki.org/wiki/Wikimedia_Discovery/Search/Glossary">Wikimedia Discovery/Search/Glossary</a></li></ol>

### Software

```{r packages_refs, results = 'asis', echo = FALSE}
c("base", "stats", "utils", "magrittr", "ggplot2", "dplyr", "tidyr", "readr", "binom", "rmarkdown", "knitr") %>%
  lapply(function(pkg) { return(format(citation(package = pkg), "text")) }) %>%
  unique %>%
  unlist %>%
  {
    paste0("<li id=\"ref-", (1:length(.)) + 4, "\">", ., "</li>")
  } %>%
  paste(collapse = "") %>%
  gsub("<URL:", "", ., fixed = TRUE) %>%
  gsub(">.", "", ., fixed = TRUE) %>%
  paste0("<ol start = \"2\" style = \"list-style-type: decimal\">", ., "</ol>", collapse = "") %>%
  gsub("\n", "", .) %>%
  cat
```
